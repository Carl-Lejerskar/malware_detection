import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
import numpy as np
import pickle


SEED = 101010  # Seed for random operations


def train_model(X, y, model, seed):
    """
    Train a given model and print relevant performance metrics.
    """
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=seed, stratify=y
    )

    non_bool_columns = [col for col in df.columns if df[col].nunique() > 2]
    preprocessor = ColumnTransformer(
        transformers=[("num", StandardScaler(), non_bool_columns)],
        remainder="passthrough",
    )
    X_train = pd.DataFrame(preprocessor.fit_transform(X_train), columns=X_train.columns)
    X_test = pd.DataFrame(preprocessor.transform(X_test), columns=X_test.columns)

    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    print("Accuracy:", accuracy_score(y_test, preds))
    print("Precision:", precision_score(y_test, preds))
    print("Recall:", recall_score(y_test, preds))
    print("F1 Score:", f1_score(y_test, preds))

    return model, preprocessor


def preprocess_data(df, high_risk_permissions):
    """
    Preprocesses the data by applying Chi-square feature selection,
    and adding new features related to permissions.

    Additionally it writes out some examples for a demo.
    """
    df = df.drop_duplicates()
    X = df.drop("Result", axis=1)
    y = df["Result"]
    pos_samples = X[y == 1].sample(5, random_state=SEED)
    neg_samples = X[y == 0].sample(5, random_state=SEED)
    pos_samples.to_json("artifacts/test_input_positive.json", orient="records")
    neg_samples.to_json("artifacts/test_input_negative.json", orient="records")

    # New feature calculations
    X_transformed = X.copy()
    X_transformed["enabled_permission_count"] = X.sum(axis=1)
    X_transformed["any_high_risk"] = X[high_risk_permissions].sum(axis=1) > 0
    X_transformed["count_high_risk"] = X[high_risk_permissions].sum(axis=1)

    # Chi-Squared Feature Selection
    chi2_selector = SelectKBest(chi2, k="all")
    chi2_selector.fit(X_transformed, y)
    chi2_scores = pd.DataFrame(
        list(zip(X_transformed.columns, chi2_selector.scores_, chi2_selector.pvalues_)),
        columns=["Feature", "Chi2 Score", "P-value"],
    )
    chi2_scores = chi2_scores.sort_values(by="P-value", ascending=True)
    selected_features = chi2_scores[chi2_scores["P-value"] <= 0.05]["Feature"]
    X_transformed = X_transformed[selected_features]

    return X_transformed, y


def write_artifacts(model, preprocessor):
    """
    Pickles and saves model/preprocessor to `artifacts/`
    """
    with open("artifacts/gradient_boosting_malware_model.pkl", "wb") as file:
        pickle.dump(model, file)

    with open("artifacts/preprocessor.pkl", "wb") as file:
        pickle.dump(preprocessor, file)
    return


if __name__ == "__main__":
    df = pd.read_csv("../data/Malware_detection_data.csv")
    high_risk_permissions = [
        "com.android.launcher.permission.INSTALL_SHORTCUT",
        "android.permission.READ_PHONE_STATE",
        "android.permission.RECEIVE_BOOT_COMPLETED",
    ]
    X, y = preprocess_data(df, high_risk_permissions)
    model_parameters = {
        "learning_rate": 0.1,
        "max_depth": 3,
        "max_features": "log2",
        "min_samples_leaf": 2,
        "min_samples_split": 2,
        "n_estimators": 250,
    }
    gb_model = GradientBoostingClassifier(**model_parameters, random_state=SEED)
    model, preprocessor = train_model(X, y, gb_model, SEED)
    write_artifacts(model, preprocessor)
